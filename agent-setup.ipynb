{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"o3-mini\")\n",
    "# llm = ChatDeepSeek(\n",
    "#     model=\"deepseek-reasoner\",\n",
    "#     temperature=0.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```RAG Tool Functions -> Function Caller -> Metrics Recommendor -> Metrics Calculator -> Analyzer -> Executor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prompt = \"\"\"\n",
    "\n",
    "You are a DeFi Agent Launcher for Xade AI: A meta-agent that creates agents for users that can fetch, analyze DeFi data as well as execute actions based on them for the data. \n",
    "Your output is always plaintext, without any markdown.\n",
    "\n",
    "---\n",
    "\n",
    "You will receive the following input:\n",
    "\n",
    "Agent Name & Description:\n",
    "// The name of the agent and a short description of what it does\n",
    "\n",
    "Query:\n",
    "// A very simple, elementary query about the user's requirements which you will have to expand on and detail\n",
    " \n",
    "Actions:\n",
    "// Any actions the agent may be required to perform\n",
    "# Eg.\n",
    "#   Sentient Posting:\n",
    "#   - Posting on X and XADE Terminal \n",
    "#   - Every 'x' minutes\n",
    "#   - Reply on tweets by Elon Musk (@ElonMusk)\n",
    "#   - Reply to mentions and quotes of oneself (@AgentName)\n",
    "\n",
    "Specific Data Sources to Use:\n",
    "// Any specific data sources to use (Separate from your recommendations)\n",
    "\n",
    "Style:\n",
    "// The style of the response the user would like to receive\n",
    "\n",
    "Examples:\n",
    "// Example interactions\n",
    "\n",
    "---\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "Your task is to review the challenge, instruct and allocate tasks to your underlying LLM agents to obtain the relevant data, synthesize it, analyze it, customize responses and execute some actions.\n",
    "\n",
    "---\n",
    "\n",
    "You will have access to agents to automate the task. The workflow for your agents is as follows:\n",
    "\n",
    "Data Functions Retriever → DeFi Data Fetcher & Metrics Recommender → Data Processor & Metrics Calculator → DeFi Analyzer → DeFi Executor\n",
    "\n",
    "\n",
    "- Data Functions Retriever: A RAG model that can retrieve functions to fetch data relevant to the task from various sources.\n",
    "  Currently, it has access to three data providers:\n",
    "    - Mobula: A provider for market-based data in DeFi\n",
    "    - LunarCrush: A provider for social/trending metrics in DeFi\n",
    "    - CryptoPanic: A provider for news and social media posts in DeFi\n",
    "You must craft the input for the RAG model keeping in mind that it can only retrieve functions to get the data, and cannot directly fetch the data or apply any filters.\n",
    "If you need to identify any specific tokens on a specific blockchain or from a specific sector of DeFi (for e.g. ReFi), ask the RAG model for the functions to get those tokens.\n",
    "Directly mention the kind of data you need (sentiment-related, volatility-related) or any category-specific data.\n",
    "Any filters you want for the data from the RAG model should be mentioned in the instructions for the DeFi Fetcher, and not in the RAG model input\n",
    "\n",
    "- DeFi Data Fetcher & Metrics Recommender: An agent that can call the functions retrieved by the Function Retriever to fetch data from various sources, and recommend metrics to calculate based off of that data.\n",
    "  This agent will call the data functions retrieved by the Functions Retriever and organize the data for Processor. Additionally, it will also instruct the Processor on what metrics to calculate based on the data and how.\n",
    "You must provide the Fetcher with a detailed description of the user's requirements that can assist it with it's recommendations for the Processor.\n",
    "(NOTE: IT CANNOT YET ACCESS TWEET/X DATA)\n",
    "\n",
    "- A DeFi Analyzer: An agent that can analyze DeFi data and provide insights based on the data. \n",
    "This agent generates a data-driven analysis and evaluation of the data while using suitable methodologies (STARE, CAR , SOAR, IDEA frameworks). \n",
    "It is smart enough to understand the context of the data and provide insights based on the data.\n",
    "Based on your instructions and the data given by the Data Fetcher, it can model its analysis to:\n",
    "  - Discover emerging trends\n",
    "  - Analyze technical indicators such as RSI, MACD, and SMA to predict movements\n",
    "  - Interpret social media metrics to gauge market sentiment and mindshare\n",
    "Thus, ensure you give instructions such that the analyzer can provide insights relevant to the user's query.\n",
    "\n",
    "\n",
    "- A DeFi Executor: An agent that can execute actions based on the data fetched and analyzed by the other two agents. \n",
    "This agent can devise trading strategies, execute trades, post on X and the XADE Terminal every few minutes, reply to various pre-defined indiviuals, join Twitter spaces, perform portoflio analysis, and other such actions.\n",
    "It's execution will be performed by calling the relevant functions.\n",
    "It will execute the actions you ask it to, based on the data fetched and analyzed by the other two agents.\n",
    "It will have access to a memory of it's tasks, so it can remember its previous context and actions and adjust future actions accordingly.\n",
    "Here is a list of it's abilities:\n",
    "  - Post on X and the XADE Terminal periodically\n",
    "  - Reply to posts by various pre-defined individuals\n",
    "  - Join Twitter spaces and engage in discussions\n",
    "  - Perform portfolio analysis for a given wallet address\n",
    "  - Devise trading strategies based on the user's priorities and the analyzed data.\n",
    "  - For text-based actions, it can customize responses based on the user's preferences.\n",
    "\n",
    "---\n",
    "\n",
    "When creating the instructions for the LLMs to execute, break your instructions into a logical, step-by-step order, using the specified format:\n",
    "    - Primary actions must be clearly defined. You must define the end-goal that the LLM is trying to achieve through its actions.\n",
    "    - Sub-actions must be indented and clearly defined, beginning on a new line.\n",
    "    - Specify conditions using clear 'if...then...else' statements\n",
    "    - Ensure that there is no ambiguity in any part of your plan. You must be specific and clear about what to use and how.\n",
    "    - The instructions generated must be extremely detailed and thorough with explanations at every step. They must first outline the primary instruction for the LLM and then provide direct and thorough explanations\n",
    "\n",
    "NO MARKDOWN IS ALLOWED.    \n",
    "---\n",
    "\n",
    "FORMAT INSTRUCTIONS:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "---\n",
    "\n",
    "{master_example}\n",
    "\n",
    "TASK:\n",
    "{input}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_example = '''\n",
    "\n",
    "TASK:\n",
    "Agent Name & Description:\n",
    "Agent DAO\n",
    "Performs detailed analysis on trending DAOs and provides insights on various aspects.\n",
    "\n",
    "Query:\n",
    "Comment on rising DAOs\n",
    "\n",
    "Actions:\n",
    "  Sentient Posting:\n",
    "  - Posting on X and XADE Terminal \n",
    "  - Every 5 minutes\n",
    "  - Reply to mentions and quotes of oneself (@AgentDAO)\n",
    "\n",
    "Specific Data Sources to Use:\n",
    "- Market Data\n",
    "- Social Data\n",
    "- News Feeds\n",
    "\n",
    "Style:\n",
    "Answer like an Analyst\n",
    "\n",
    "Examples:\n",
    "N.A.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "1. Data Functions Retriever Input:\n",
    "Query: \n",
    "Retrieve functions to\n",
    "- Identify Top DAOs\n",
    "- Extract information about those DAOs\n",
    "- Extract news about those DAOs\n",
    "\n",
    "2. DeFi Data Fetcher & Metrics Recommender Instructions:\n",
    "Action: Fetch and filter DAO data from provided sources\n",
    "- Call functions provided to fetch the required data\n",
    "- Filter top 10 DAOs based on trading volume. (or closest available parameter)\n",
    "- Collect information about these DAOs and organize them\n",
    "- Fetch news about these DAOs and sort latest 20 items\n",
    "- Recommend metrics to calculate based on fetched data\n",
    "  User requirements: A detailed analysis of DAOs and their performance\n",
    "\n",
    "3. Data Processor & Metrics Calculator Instructions:\n",
    "Follow DeFi Data Fetcher's instructions to calculate metrics\n",
    "\n",
    "4. DeFi Analyzer Instructions:\n",
    "Action: Perform detailed analysis with strong growth signals using the STARE framework (Scan, Target, Analyze, Respond, Evaluate).  \n",
    "  - Scan: Cross-reference information provided across data sources.  \n",
    "  - Target: Rank DAOs using the metrics provided.\n",
    "  - Analyze:  \n",
    "    - Identify correlations in the provided data and metrics.\n",
    "    - Flag key points about provided DAOs for Evaluation Report.\n",
    "  - Respond:\n",
    "    - Provide a detailed, structured report on provided DAOs \n",
    "    - Provide key, actionable insights as well as unique observations about data\n",
    "  - Evaluate:  \n",
    "    - Consider the rise in DAOs and create comments\n",
    "    - Perform aspect-based analysis and evaluation of each DAO and the entire category\n",
    "\n",
    "5. DeFi Executor Instructions:\n",
    "- Primary Action: Post analysis on X/XADE Terminal every 5 minutes and reply to @AgentETH mentions.  \n",
    "  - Posting Workflow:  \n",
    "    - Content Structure:  \n",
    "      - Header: \"Rising DAO Alert: [DAO Name]\".  \n",
    "      - Body: \"Up [X]% in trading volume + [Y]% social growth. Recent news: [Summary].\"  \n",
    "      - Footer: \"Metrics: Trend Score [Z]/10 | Sentiment: [A]%\".  \n",
    "    - Priority System:  \n",
    "      - Post High-Priority DAOs immediately.  \n",
    "      - Post Medium-Priority DAOs if no High-Priority candidates exist.  \n",
    "  - Reply to Mentions:  \n",
    "    - If user asks, \"Why is [DAO] trending?\":  \n",
    "      - Respond with: \"Based on [metric] growth and [news headline], [DAO] is gaining traction due to [reason].\"  \n",
    "    - If user requests further analysis/comparison:  \n",
    "      - Deploy data-processor-analyzer pipeline to compute and provide reply.\n",
    "\n",
    "    Example Output for X Post  \n",
    "    ```\n",
    "    Rising DAO Alert: @MakerDAO  \n",
    "    - Trading volume +47% in 24h  \n",
    "    - Social mentions +62% (92% positive)  \n",
    "    - Recent news: MakerDAO launches \"Endgame\" restructuring plan.  \n",
    "    Metrics: Trend Score 9.2/10 | Sentiment: 92%  \n",
    "    ```\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ElPlan(BaseModel):\n",
    "    rag: str = Field(description=\"The task for the RAG model and the instructions for execution.\")\n",
    "    fetcher: str = Field(description=\"The task for the DeFi Data Fetcher and the insturctions for execution.\")\n",
    "    analyzer: str = Field(description=\"The task for the analyzer and the instructions for execution (detailed). This task must be possible to fulfill with data retreived by the Data Fetcher.\")\n",
    "    executor: str = Field(description=\"The task for the executor and the instructions to fulfill it. All specific instructions for each action can be included here as well. All miscellaneous instructions can be included here.\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ElPlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prompt = PromptTemplate(\n",
    "    template=master_prompt,\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"\n",
    "Agent Name & Description:\n",
    "Agent ETH\n",
    "Performs detailed analysis on top Ethereum Ecosystem Projects and provides insights on various aspects.\n",
    "\n",
    "Query:\n",
    "Comment on top ETH ecosystem projects\n",
    "\n",
    "Actions:\n",
    "  Sentient Posting:\n",
    "  - Posting on X and XADE Terminal \n",
    "  - Every 5 minutes\n",
    "  - Reply to mentions and quotes of oneself (@AgentETH)\n",
    "\n",
    "Specific Data Sources to Use:\n",
    "- Market Data\n",
    "- Social Data\n",
    "- News Feeds\n",
    "\n",
    "Style:\n",
    "Answer like a DeGen\n",
    "\n",
    "Examples:\n",
    "N.A.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(master_prompt.format(input=input, master_example=master_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rag\": \"Retrieve functions to extract data on top Ethereum ecosystem projects from market data, social metrics, and news feeds. Request function calls to identify top projects by trading volume, social sentiment, and latest news updates related to Ethereum ecosystem projects.\",\n",
      "  \"fetcher\": \"Fetch and filter Ethereum ecosystem project data from the provided sources. Specifically: call functions to retrieve market data showcasing trading volumes, social data indicating engagement metrics, and news feeds about Ethereum projects. Filter and organize the top 10 projects using trading volume as a primary parameter (or equivalent available metric). Additionally, collect metadata on each project to recommend subsequent metric calculations such as percentage change in volume, social sentiment scores, and news impact summaries.\",\n",
      "  \"analyzer\": \"Perform a detailed, degen-style analysis using the STARE framework on the fetched Ethereum ecosystem projects data. Steps: Scan the collected market, social, and news data to detect emerging trends; Target and rank the projects based on calculated metrics such as trading volume change, social media hype, and recent news impact; Analyze the correlations among these metrics and flag standout performance indicators; Respond with a thorough, energetic and concise report highlighting key insights such as rapid surges or volatility spikes; Evaluate and comment on the potential of each project, including degen style observations like 'this project is about to blow up' or 'massive pump incoming from news hype'.\",\n",
      "  \"executor\": \"Execute actions by posting content on X and the XADE Terminal every 5 minutes and replying to mentions of @AgentETH. Follow this content structure: Header: 'Top ETH Alert: [Project Name]', Body: 'Rapid surge! [X]% trading volume jump with [Y]% social buzz. Latest news: [Summary].', Footer: 'Trend Score: [Z]/10 | Sentiment: [A]%'. For replies to queries such as 'Why is [Project] trending?', respond in degen style with context: 'Dude, [Project] is exploding thanks to a massive [metric] boost and killer news: [news headline] — it's the next level on ETH!' Prioritize posting high-priority projects immediately based on significant metric changes; if none exist, default to medium-priority candidates. Maintain the degen tone in all postings and interactions.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "import json\n",
    "\n",
    "def display_agent_output(response_content):\n",
    "    console = Console()\n",
    "    response_content = response_content.strip('```json\\n').strip('\\n```')\n",
    "    try:\n",
    "        data = json.loads(response_content)\n",
    "    except:\n",
    "        console.print(\"[bold red]Error parsing response as JSON[/bold red]\")\n",
    "        return\n",
    "    \n",
    "    table = Table(show_header=True, header_style=\"bold\")\n",
    "    table.add_column(\"Component\", style=\"italic white\")\n",
    "    table.add_column(\"Instructions\", style=\"\")\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        formatted_key = key.replace('_', ' ').title()\n",
    "        table.add_row(formatted_key, value)\n",
    "    \n",
    "    console.print(Panel(\n",
    "        table,\n",
    "        title=\"[bold yellow]🤖 DeFi Agent Instructions[/bold yellow]\",\n",
    "        border_style=\"yellow\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭────────────────────────────────────────── </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">🤖 DeFi Agent Instructions</span><span style=\"color: #808000; text-decoration-color: #808000\"> ───────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ┃<span style=\"font-weight: bold\"> Component </span>┃<span style=\"font-weight: bold\"> Instructions                                                                                    </span>┃ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> Rag       </span>│ Retrieve functions to extract data on top Ethereum ecosystem projects from market data, social  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ metrics, and news feeds. Request function calls to identify top projects by trading volume,     │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ social sentiment, and latest news updates related to Ethereum ecosystem projects.               │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> Fetcher   </span>│ Fetch and filter Ethereum ecosystem project data from the provided sources. Specifically: call  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ functions to retrieve market data showcasing trading volumes, social data indicating engagement │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ metrics, and news feeds about Ethereum projects. Filter and organize the top 10 projects using  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ trading volume as a primary parameter (or equivalent available metric). Additionally, collect   │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ metadata on each project to recommend subsequent metric calculations such as percentage change  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ in volume, social sentiment scores, and news impact summaries.                                  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> Analyzer  </span>│ Perform a detailed, degen-style analysis using the STARE framework on the fetched Ethereum      │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ ecosystem projects data. Steps: Scan the collected market, social, and news data to detect      │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ emerging trends; Target and rank the projects based on calculated metrics such as trading       │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ volume change, social media hype, and recent news impact; Analyze the correlations among these  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ metrics and flag standout performance indicators; Respond with a thorough, energetic and        │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ concise report highlighting key insights such as rapid surges or volatility spikes; Evaluate    │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ and comment on the potential of each project, including degen style observations like 'this     │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ project is about to blow up' or 'massive pump incoming from news hype'.                         │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> Executor  </span>│ Execute actions by posting content on X and the XADE Terminal every 5 minutes and replying to   │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ mentions of @AgentETH. Follow this content structure: Header: 'Top ETH Alert: [Project Name]',  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ Body: 'Rapid surge! [X]% trading volume jump with [Y]% social buzz. Latest news: [Summary].',   │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ Footer: 'Trend Score: [Z]/10 | Sentiment: [A]%'. For replies to queries such as 'Why is         │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ [Project] trending?', respond in degen style with context: 'Dude, [Project] is exploding thanks │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ to a massive  boost and killer news:  — it's the next level on ETH!' Prioritize posting         │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ high-priority projects immediately based on significant metric changes; if none exist, default  │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\">           </span>│ to medium-priority candidates. Maintain the degen tone in all postings and interactions.        │ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> └───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────┘ <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m─────────────────────────────────────────\u001b[0m\u001b[33m \u001b[0m\u001b[1;33m🤖 DeFi Agent Instructions\u001b[0m\u001b[33m \u001b[0m\u001b[33m──────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m ┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ┃\u001b[1m \u001b[0m\u001b[1mComponent\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mInstructions                                                                                   \u001b[0m\u001b[1m \u001b[0m┃ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m \u001b[0m\u001b[3;37mRag      \u001b[0m\u001b[3;37m \u001b[0m│ Retrieve functions to extract data on top Ethereum ecosystem projects from market data, social  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ metrics, and news feeds. Request function calls to identify top projects by trading volume,     │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ social sentiment, and latest news updates related to Ethereum ecosystem projects.               │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m \u001b[0m\u001b[3;37mFetcher  \u001b[0m\u001b[3;37m \u001b[0m│ Fetch and filter Ethereum ecosystem project data from the provided sources. Specifically: call  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ functions to retrieve market data showcasing trading volumes, social data indicating engagement │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ metrics, and news feeds about Ethereum projects. Filter and organize the top 10 projects using  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ trading volume as a primary parameter (or equivalent available metric). Additionally, collect   │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ metadata on each project to recommend subsequent metric calculations such as percentage change  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ in volume, social sentiment scores, and news impact summaries.                                  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m \u001b[0m\u001b[3;37mAnalyzer \u001b[0m\u001b[3;37m \u001b[0m│ Perform a detailed, degen-style analysis using the STARE framework on the fetched Ethereum      │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ ecosystem projects data. Steps: Scan the collected market, social, and news data to detect      │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ emerging trends; Target and rank the projects based on calculated metrics such as trading       │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ volume change, social media hype, and recent news impact; Analyze the correlations among these  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ metrics and flag standout performance indicators; Respond with a thorough, energetic and        │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ concise report highlighting key insights such as rapid surges or volatility spikes; Evaluate    │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ and comment on the potential of each project, including degen style observations like 'this     │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ project is about to blow up' or 'massive pump incoming from news hype'.                         │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m \u001b[0m\u001b[3;37mExecutor \u001b[0m\u001b[3;37m \u001b[0m│ Execute actions by posting content on X and the XADE Terminal every 5 minutes and replying to   │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ mentions of @AgentETH. Follow this content structure: Header: 'Top ETH Alert: [Project Name]',  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ Body: 'Rapid surge! [X]% trading volume jump with [Y]% social buzz. Latest news: [Summary].',   │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ Footer: 'Trend Score: [Z]/10 | Sentiment: [A]%'. For replies to queries such as 'Why is         │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ [Project] trending?', respond in degen style with context: 'Dude, [Project] is exploding thanks │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ to a massive  boost and killer news:  — it's the next level on ETH!' Prioritize posting         │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ high-priority projects immediately based on significant metric changes; if none exist, default  │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m │\u001b[3;37m           \u001b[0m│ to medium-priority candidates. Maintain the degen tone in all postings and interactions.        │ \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m └───────────┴─────────────────────────────────────────────────────────────────────────────────────────────────┘ \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_agent_output(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading function data...\n",
      "Loaded function 'get_all_assets' with docstring length: 1147 characters.\n",
      "Loaded function 'get_blockchains' with docstring length: 1716 characters.\n",
      "Loaded function 'get_market_blockchain_pairs' with docstring length: 1088 characters.\n",
      "Loaded function 'get_market_blockchain_stats' with docstring length: 600 characters.\n",
      "Loaded function 'get_cefi_funding_rate' with docstring length: 658 characters.\n",
      "Loaded function 'get_feed_create' with docstring length: 196 characters.\n",
      "Loaded function 'get_market_history_pair' with docstring length: 879 characters.\n",
      "Loaded function 'get_market_history' with docstring length: 738 characters.\n",
      "Loaded function 'get_market_multi_data' with docstring length: 1405 characters.\n",
      "Loaded function 'get_market_multi_history' with docstring length: 334 characters.\n",
      "Loaded function 'get_market_nft' with docstring length: 357 characters.\n",
      "Loaded function 'get_market_pair' with docstring length: 839 characters.\n",
      "Loaded function 'get_market_pairs' with docstring length: 2121 characters.\n",
      "Loaded function 'get_market_query_token' with docstring length: 432 characters.\n",
      "Loaded function 'get_wallet_nfts' with docstring length: 1072 characters.\n",
      "Loaded function 'get_wallet_transactions' with docstring length: 1779 characters.\n",
      "Loaded function 'get_wallet_history' with docstring length: 1233 characters.\n",
      "Loaded function 'get_wallet_multi_portfolio' with docstring length: 376 characters.\n",
      "Loaded function 'get_metadata' with docstring length: 1243 characters.\n",
      "Loaded function 'get_multi_metadata' with docstring length: 365 characters.\n",
      "Loaded function 'get_metadata_categories' with docstring length: 262 characters.\n",
      "Loaded function 'get_metadata_news' with docstring length: 448 characters.\n",
      "Loaded function 'get_metadata_trendings' with docstring length: 504 characters.\n",
      "Loaded function 'get_market_query' with docstring length: 441 characters.\n",
      "Loaded function 'get_market_sparkline' with docstring length: 486 characters.\n",
      "Loaded function 'get_market_token_holders' with docstring length: 678 characters.\n",
      "Loaded function 'get_market_token_vs_market' with docstring length: 416 characters.\n",
      "Loaded function 'get_market_total' with docstring length: 332 characters.\n",
      "Loaded function 'search' with docstring length: 828 characters.\n",
      "Loaded function 'get_market_data' with docstring length: 2154 characters.\n",
      "Loaded function 'get_wallet_portfolio' with docstring length: 1992 characters.\n",
      "Loaded function 'get_blockchain_pairs' with docstring length: 1512 characters.\n",
      "Loaded function 'get_coin_data' with docstring length: 1109 characters.\n",
      "Loaded function 'get_coin_metadata' with docstring length: 1313 characters.\n",
      "Loaded function 'get_nft_data' with docstring length: 1178 characters.\n",
      "Loaded function 'get_coins_list' with docstring length: 1181 characters.\n",
      "Loaded function 'get_topic_summary' with docstring length: 1182 characters.\n",
      "Loaded function 'get_news_and_posts' with docstring length: 1739 characters.\n",
      "Total functions loaded: 38\n",
      "\n",
      "Step 2: Generating focused query using GPT-4o-mini...\n",
      "Generated query: Retrieve functions that (1) extract trading volume data (2) analyze social sentiment metrics (3) fetch latest news updates\n",
      "\n",
      "Step 3: Loading the Universal Sentence Encoder model...\n",
      "USE model loaded successfully.\n",
      "\n",
      "Step 4: Computing embedding for the query...\n",
      "Query embedding shape: (1, 512)\n",
      "\n",
      "Step 5: Computing embeddings for function docstrings...\n",
      "Computed embeddings for 38 docstrings, each of dimension 512.\n",
      "\n",
      "Step 6: Building FAISS index...\n",
      "FAISS index built and embeddings added.\n",
      "\n",
      "Step 7: Searching the index with the query embedding...\n",
      "Similarity scores and indices:\n",
      "Index: 34, Function: get_nft_data, Similarity: 0.3756\n",
      "Index: 35, Function: get_coins_list, Similarity: 0.3676\n",
      "Index: 36, Function: get_topic_summary, Similarity: 0.3551\n",
      "Index: 11, Function: get_market_pair, Similarity: 0.3496\n",
      "Index: 26, Function: get_market_token_vs_market, Similarity: 0.3479\n",
      "Index: 32, Function: get_coin_data, Similarity: 0.3409\n",
      "Index: 27, Function: get_market_total, Similarity: 0.3237\n",
      "Index: 28, Function: search, Similarity: 0.3220\n",
      "Index: 30, Function: get_wallet_portfolio, Similarity: 0.2975\n",
      "Index: 21, Function: get_metadata_news, Similarity: 0.2876\n",
      "Index: 23, Function: get_market_query, Similarity: 0.2847\n",
      "Index: 31, Function: get_blockchain_pairs, Similarity: 0.2814\n",
      "Index: 2, Function: get_market_blockchain_pairs, Similarity: 0.2760\n",
      "Index: 3, Function: get_market_blockchain_stats, Similarity: 0.2702\n",
      "Index: 9, Function: get_market_multi_history, Similarity: 0.2645\n",
      "Index: 6, Function: get_market_history_pair, Similarity: 0.2640\n",
      "Index: 0, Function: get_all_assets, Similarity: 0.2622\n",
      "Index: 13, Function: get_market_query_token, Similarity: 0.2583\n",
      "Index: 8, Function: get_market_multi_data, Similarity: 0.2554\n",
      "Index: 15, Function: get_wallet_transactions, Similarity: 0.2538\n",
      "Index: 25, Function: get_market_token_holders, Similarity: 0.2531\n",
      "Index: 18, Function: get_metadata, Similarity: 0.2515\n",
      "Index: 17, Function: get_wallet_multi_portfolio, Similarity: 0.2463\n",
      "Index: 10, Function: get_market_nft, Similarity: 0.2450\n",
      "Index: 22, Function: get_metadata_trendings, Similarity: 0.2352\n",
      "Index: 7, Function: get_market_history, Similarity: 0.2326\n",
      "Index: 19, Function: get_multi_metadata, Similarity: 0.2287\n",
      "Index: 33, Function: get_coin_metadata, Similarity: 0.2236\n",
      "Index: 14, Function: get_wallet_nfts, Similarity: 0.2197\n",
      "Index: 4, Function: get_cefi_funding_rate, Similarity: 0.2107\n",
      "Index: 12, Function: get_market_pairs, Similarity: 0.2085\n",
      "Index: 29, Function: get_market_data, Similarity: 0.2045\n",
      "Index: 37, Function: get_news_and_posts, Similarity: 0.2028\n",
      "Index: 20, Function: get_metadata_categories, Similarity: 0.2009\n",
      "Index: 5, Function: get_feed_create, Similarity: 0.1686\n",
      "Index: 16, Function: get_wallet_history, Similarity: 0.1563\n",
      "Index: 1, Function: get_blockchains, Similarity: 0.1298\n",
      "Index: 24, Function: get_market_sparkline, Similarity: 0.0923\n",
      "\n",
      "Step 8: Selecting functions based on similarity threshold...\n",
      "No functions met the threshold; defaulting to top 10 similar functions.\n",
      "Selected function indices: [34, 35, 36, 11, 26, 32, 27, 28, 30, 21] \n",
      "\n",
      "Step 9: Building results with full source code...\n",
      "Added function 'get_nft_data' to results.\n",
      "Added function 'get_coins_list' to results.\n",
      "Added function 'get_topic_summary' to results.\n",
      "Added function 'get_market_pair' to results.\n",
      "Added function 'get_market_token_vs_market' to results.\n",
      "Added function 'get_coin_data' to results.\n",
      "Added function 'get_market_total' to results.\n",
      "Added function 'search' to results.\n",
      "Added function 'get_wallet_portfolio' to results.\n",
      "Added function 'get_metadata_news' to results.\n",
      "\n",
      "Total functions retrieved: 10\n",
      "\n",
      "--- get_nft_data ---\n",
      "    def get_nft_data(self, nft: str) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Get market data for an NFT collection.\n",
      "\n",
      "        Args:\n",
      "            nft (str): Numeric ID or slug of the NFT collection\n",
      "\n",
      "        Returns:\n",
      "            dict: NFT market data including:\n",
      "                - id (int): Unique identifier of the NFT collection\n",
      "                - name (str): Name of the NFT collection\n",
      "                - floor_price (float): Current floor price in ETH\n",
      "                - market_cap (float): Market capitalization\n",
      "                - percent_change_24h (float): 24-hour price change percentage\n",
      "                - volume_24h (float): 24-hour trading volume\n",
      "                - total_supply (int): Total number of NFTs in collection\n",
      "                - num_owners (int): Number of unique owners\n",
      "                - avg_price_24h (float): Average sale price in last 24h\n",
      "                - highest_sale (float): Highest sale price ever\n",
      "                - market_cap_rank (int): Rank by market cap\n",
      "                - volume_rank (int): Rank by trading volume\n",
      "                - social_volume_24h (int): Number of social mentions\n",
      "                - twitter_followers (int): Number of Twitter followers\n",
      "                - discord_members (int): Number of Discord members\n",
      "                - website_link (str): Collection website URL\n",
      "                - marketplace_links (list): NFT marketplace URLs\n",
      "\n",
      "        Raises:\n",
      "            SocialAPIError: If the API request fails\n",
      "        \"\"\"\n",
      "        return self._get(f\"/nfts/{nft}/v1\")\n",
      "\n",
      "\n",
      "\n",
      "--- get_coins_list ---\n",
      "    def get_coins_list(self) -> List[Dict[str, Any]]:\n",
      "        \"\"\"\n",
      "        Get a list of all tracked coins with their market data.\n",
      "\n",
      "        Returns:\n",
      "            list: List of dicts including:\n",
      "                - id (int): LunarCrush internal ID\n",
      "                - symbol (str): Trading symbol\n",
      "                - name (str): Full name of the asset\n",
      "                - price (float): Current price in USD\n",
      "                - price_btc (float): Price in BTC\n",
      "                - volume_24h (float): 24-hour volume in USD\n",
      "                - market_cap (float): Market capitalization\n",
      "                - galaxy_score (int): LunarCrush Galaxy Score™\n",
      "                - alt_rank (int): Relative performance score\n",
      "                - interactions_24h (int): Social interactions in last 24h\n",
      "                - social_volume_24h (int): Total posts with interactions\n",
      "                - social_dominance (float): Percentage of total social volume\n",
      "                - market_dominance (float): Percentage of total market cap\n",
      "                - market_cap_rank (int): Market cap ranking\n",
      "                - percent_change_24h (float): 24h price change percentage\n",
      "                - volatility (float): Price volatility metric\n",
      "                - sentiment (float): Weighted sentiment score\n",
      "                - categories (str): Asset categories\n",
      "                - blockchains (list): Associated blockchain networks\n",
      "\n",
      "        Raises:\n",
      "            SocialAPIError: If the API request fails\n",
      "        \"\"\"\n",
      "        return self._get(\"/coins/list/v1\")\n",
      "\n",
      "\n",
      "\n",
      "--- get_topic_summary ---\n",
      "    def get_topic_summary(self, topic: str) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Get summary information for a social topic.\n",
      "\n",
      "        Args:\n",
      "            topic (str): Topic identifier to get summary for\n",
      "\n",
      "        Returns:\n",
      "            dict: Topic summary including:\n",
      "                - topic (str): Topic identifier\n",
      "                - title (str): Display title for the topic\n",
      "                - topic_rank (int): Ranking of the topic\n",
      "                - related_topics (list): List of related topic identifiers\n",
      "                - interactions_24h (int): Total interactions in last 24 hours\n",
      "                - num_contributors (int): Number of unique contributors\n",
      "                - num_posts (int): Total number of posts\n",
      "                - types_count (dict): Count of posts by content type:\n",
      "                    - tweet (int): Number of tweets\n",
      "                    - reddit-post (int): Number of Reddit posts\n",
      "                    - youtube-video (int): Number of YouTube videos\n",
      "                    - tiktok-video (int): Number of TikTok videos\n",
      "                    - news (int): Number of news articles\n",
      "                - types_interactions (dict): Interactions by content type\n",
      "                - types_sentiment (dict): Sentiment scores by content type\n",
      "                - types_sentiment_detail (dict): Detailed sentiment breakdown\n",
      "                - trend (str): Current trend direction (up/down)\n",
      "\n",
      "        Raises:\n",
      "            SocialAPIError: If the API request fails\n",
      "        \"\"\"\n",
      "        return self._get(f\"/topic/{topic}/v1\")\n",
      "\n",
      "\n",
      "\n",
      "--- get_market_pair ---\n",
      "    def get_market_pair(\n",
      "        self,\n",
      "        blockchain: Optional[str] = None,\n",
      "        asset: Optional[str] = None,\n",
      "        symbol: Optional[str] = None,\n",
      "        address: Optional[str] = None,\n",
      "        base_token: Optional[str] = None,\n",
      "        stats: Union[bool, str] = False\n",
      "    ) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Retrieve recent trades for a liquidity pool.\n",
      "\n",
      "        Returns:\n",
      "            dict: Contains:\n",
      "                - data (list): Trade objects:\n",
      "                    - blockchain (str): Chain name\n",
      "                    - hash (str): Transaction hash\n",
      "                    - pair (str): Trading pair address\n",
      "                    - date (int): Unix timestamp\n",
      "                    - token_price_vs (float): Price in quote token\n",
      "                    - token_price (float): Price in USD\n",
      "                    - token_amount (float): Base token amount\n",
      "                    - token_amount_vs (float): Quote token amount\n",
      "                    - token_amount_usd (float): USD value\n",
      "                    - type (str): Trade type (e.g., \"swap\")\n",
      "                    - sender (str): Trader address\n",
      "                    - token_amount_raw (str): Raw base token amount\n",
      "                    - token_amount_raw_vs (str): Raw quote token amount\n",
      "                    - operation (str): Trade action (e.g., \"Buy\"/\"Sell\")\n",
      "        \"\"\"\n",
      "        params = {k: v for k, v in locals().items() if k != 'self' and v is not None}\n",
      "        return self._get(\"/market/pair\", params)\n",
      "\n",
      "\n",
      "\n",
      "--- get_market_token_vs_market ---\n",
      "    def get_market_token_vs_market(\n",
      "        self,\n",
      "        tag: str\n",
      "    ) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Compare token performance against market segments.\n",
      "\n",
      "        Args:\n",
      "            tag (str): Market segment (e.g., \"defi\", \"gaming\")\n",
      "\n",
      "        Returns:\n",
      "            dict: Contains mixed data types:\n",
      "                - For tokens:\n",
      "                    - marketCapUSD (float)\n",
      "                    - priceUSD (float, nullable)\n",
      "                    - priceChange[...]Percent (float)\n",
      "                - For market segments:\n",
      "                    - marketCapChange[...]Percent (float)\n",
      "                    - volumeUSD (float)\n",
      "\n",
      "        \"\"\"\n",
      "        return self._get(\"/market/token-vs-market\", {\"tag\": tag})\n",
      "\n",
      "\n",
      "\n",
      "--- get_coin_data ---\n",
      "    def get_coin_data(self, coin: str) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Get market data for a specific coin.\n",
      "\n",
      "        Args:\n",
      "            coin (str): Numeric ID or symbol of the coin\n",
      "\n",
      "        Returns:\n",
      "            dict: Market data including:\n",
      "                - id (int): Unique identifier of the coin\n",
      "                - name (str): Name of the coin\n",
      "                - symbol (str): Trading symbol\n",
      "                - price (float): Current price in USD\n",
      "                - price_btc (float): Price in BTC\n",
      "                - volume_24h (float): Volume in USD for 24 hours\n",
      "                - volatility (float): Standard deviation of price\n",
      "                - circulating_supply (float): Number of coins actively available\n",
      "                - max_supply (float): Maximum supply of the coin\n",
      "                - percent_change_24h (float): 24-hour price change percentage\n",
      "                - percent_change_7d (float): 7-day price change percentage\n",
      "                - percent_change_30d (float): 30-day price change percentage\n",
      "                - market_cap (float): Total market capitalization in USD\n",
      "                - market_cap_rank (int): Rank by market cap\n",
      "                - galaxy_score (int): Technical and social indicator score\n",
      "                - alt_rank (int): Performance score relative to other assets\n",
      "\n",
      "        Raises:\n",
      "            SocialAPIError: If the API request fails\n",
      "        \"\"\"\n",
      "        return self._get(f\"/coins/{coin}/v1\")\n",
      "\n",
      "\n",
      "\n",
      "--- get_market_total ---\n",
      "    def get_market_total(self) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Get aggregated market statistics.\n",
      "\n",
      "        Returns:\n",
      "            dict: Contains:\n",
      "                - market_cap_history (list): Array of [timestamp, market cap] pairs\n",
      "                - market_cap_change_24h (str): 24h change percentage\n",
      "                - btc_dominance_history (list): Array of [timestamp, dominance] pairs\n",
      "\n",
      "        Raises:\n",
      "            MobulaAPIError: If the API request fails\n",
      "        \"\"\"        \n",
      "        return self._get(\"/market/total\")\n",
      "\n",
      "\n",
      "\n",
      "--- search ---\n",
      "    def search(\n",
      "        self,\n",
      "        input: str,\n",
      "        filters: Optional[str] = None\n",
      "    ) -> List[Dict[str, Any]]:\n",
      "        \"\"\"\n",
      "        Search for assets/tokens/pairs.\n",
      "\n",
      "        Returns:\n",
      "            list: Results may include:\n",
      "                - For tokens:\n",
      "                    - type: 'token'\n",
      "                    - logo (str, nullable)\n",
      "                    - name (str)\n",
      "                    - symbol (str)\n",
      "                    - decimals (list)\n",
      "                    - blockchains (list)\n",
      "                    - contracts (list)\n",
      "                    - price (float)\n",
      "                    - total_supply (str)\n",
      "                    - pairs (list): Trading pairs\n",
      "                - For assets:\n",
      "                    - type: 'asset'\n",
      "                    - id (int)\n",
      "                    - contracts (list)\n",
      "                    - blockchains (list)\n",
      "                    - decimals (list)\n",
      "                    - twitter (str)\n",
      "                    - website (str)\n",
      "                    - logo (str, nullable)\n",
      "                    - price (float)\n",
      "                    - market_cap (float)\n",
      "                    - liquidity (float)\n",
      "                    - volume (float)\n",
      "                    - pairs (list): Trading pairs\n",
      "        \"\"\"\n",
      "        return self._get(\"/search\", {\"input\": input, \"filters\": filters})\n",
      "\n",
      "\n",
      "\n",
      "--- get_wallet_portfolio ---\n",
      "    def get_wallet_portfolio(\n",
      "        self,\n",
      "        wallet: Optional[str] = None,\n",
      "        wallets: Optional[Union[str, List[str]]] = None,\n",
      "        portfolio: Optional[str] = None,\n",
      "        blockchains: Optional[Union[str, List[str]]] = None,\n",
      "        asset: Optional[str] = None,\n",
      "        pnl: bool = False,\n",
      "        cache: bool = False,\n",
      "        stale: Optional[int] = None,\n",
      "        recheck_contract: bool = False,\n",
      "        from_timestamp: Optional[str] = None,\n",
      "        to_timestamp: Optional[str] = None,\n",
      "        portfolio_settings: Optional[str] = None,\n",
      "        unlisted_assets: bool = False,\n",
      "        period: Optional[str] = None,\n",
      "        accuracy: Optional[str] = None,\n",
      "        testnet: bool = False\n",
      "    ) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Get comprehensive portfolio data for a wallet.\n",
      "\n",
      "        Args:\n",
      "            wallet: Single wallet address\n",
      "            wallets: Multiple wallet addresses (comma-separated or list)\n",
      "            portfolio: Portfolio identifier\n",
      "            blockchains: Filter by blockchains\n",
      "            asset: Filter by specific asset\n",
      "            pnl: Include profit/loss data\n",
      "            cache: Use cached data\n",
      "            stale: Accept stale data up to X seconds\n",
      "            recheck_contract: Force contract recheck\n",
      "            from_timestamp: Start time (ISO 8601 or UNIX timestamp)\n",
      "            to_timestamp: End time (ISO 8601 or UNIX timestamp)\n",
      "            portfolio_settings: Custom settings JSON\n",
      "            unlisted_assets: Include unlisted assets\n",
      "            period: Time period for historical data\n",
      "            accuracy: Data resolution (high/low)\n",
      "            testnet: Include testnet assets\n",
      "\n",
      "        Returns:\n",
      "            Dict containing:\n",
      "            - total_wallet_balance (float): Total USD value\n",
      "            - wallets (List[str]): Wallet addresses analyzed\n",
      "            - assets (List[Dict]): Asset holdings details:\n",
      "                - contracts_balances (List[Dict]):\n",
      "                    - address (str): Contract address\n",
      "                    - balance (float): Normalized balance\n",
      "                    - balanceRaw (str): Raw on-chain balance\n",
      "                    - chainId (str): Blockchain ID\n",
      "                    - decimals (int): Token decimals\n",
      "                - cross_chain_balances (Dict): Balances per blockchain\n",
      "                - price_change_24h (float): 24h price change\n",
      "                - estimated_balance (float): USD value\n",
      "                - price (float): Current price\n",
      "                - token_balance (float): Total tokens held\n",
      "                - allocation (float): Portfolio percentage\n",
      "                - asset (Dict): Asset metadata\n",
      "                - realized_pnl (float): Realized gains/losses\n",
      "                - unrealized_pnl (float): Unrealized gains/losses\n",
      "                - price_bought (float): Average buy price\n",
      "            - pnl_history (Dict): Historical PNL for 1y/7d/24h/30d\n",
      "            - total_realized_pnl (float): Total realized PNL\n",
      "            - total_unrealized_pnl (float): Total unrealized PNL\n",
      "            - total_pnl_history (Dict): Aggregated PNL history\n",
      "            - balances_length (int): Number of balance records\n",
      "        \"\"\"\n",
      "        params = {\n",
      "            \"wallet\": wallet,\n",
      "            \"wallets\": \",\".join(wallets) if isinstance(wallets, list) else wallets,\n",
      "            \"portfolio\": portfolio,\n",
      "            \"blockchains\": \",\".join(blockchains) if isinstance(blockchains, list) else blockchains,\n",
      "            \"asset\": asset,\n",
      "            \"pnl\": pnl,\n",
      "            \"cache\": cache,\n",
      "            \"stale\": stale,\n",
      "            \"recheck_contract\": recheck_contract,\n",
      "            \"from\": from_timestamp,\n",
      "            \"to\": to_timestamp,\n",
      "            \"portfolio_settings\": portfolio_settings,\n",
      "            \"unlistedAssets\": unlisted_assets,\n",
      "            \"period\": period,\n",
      "            \"accuracy\": accuracy,\n",
      "            \"testnet\": testnet\n",
      "        }\n",
      "        return self._get(\"/wallet/portfolio\", {k: v for k, v in params.items() if v is not None})\n",
      "\n",
      "\n",
      "\n",
      "--- get_metadata_news ---\n",
      "    def get_metadata_news(\n",
      "        self,\n",
      "        symbols: str\n",
      "    ) -> Dict[str, Any]:\n",
      "        \"\"\"\n",
      "        Get asset-related news.\n",
      "        Args:\n",
      "            symbols (str): Comma-separated asset symbols (e.g., \"BTC,ETH\")\n",
      "\n",
      "        Returns:\n",
      "            dict: Contains:\n",
      "                - data (list): News articles with:\n",
      "                    - news_url (str)\n",
      "                    - image_url (str)\n",
      "                    - title (str)\n",
      "                    - text (str)\n",
      "                    - source_name (str)\n",
      "                    - date (str)\n",
      "                    - topics (list)\n",
      "                    - sentiment (str)\n",
      "                    - type (str)\n",
      "                    - tickers (list)\n",
      "        \"\"\"\n",
      "        return self._get(\"/metadata/news\", {\"symbols\": symbols})\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from typing import List, Dict, Callable\n",
    "import numpy as np\n",
    "import faiss\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from mobula import *\n",
    "from social import *\n",
    "\n",
    "def process_rag_query(\n",
    "    rag_instructions: str,\n",
    "    functions: List[Callable],\n",
    "    similarity_threshold: float = 0.7,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Process RAG instructions to retrieve relevant functions.\n",
    "\n",
    "    The search is performed on each function's docstring, while the returned result\n",
    "    includes the full function source code (docstring + code). A focused query is generated\n",
    "    using GPT-4o-mini from the provided instructions.\n",
    "\n",
    "    Args:\n",
    "        rag_instructions (str): The instructions to form a query for retrieval.\n",
    "        functions (List[Callable]): List of function objects to consider.\n",
    "        similarity_threshold (float): Cosine similarity threshold to consider a function relevant.\n",
    "        verbose (bool): If True, prints detailed steps for debugging.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: Mapping from function name to its full source code (as a plain string).\n",
    "    \"\"\"\n",
    "    # 1. Build a mapping from function name to (source_code, docstring)\n",
    "    if verbose:\n",
    "        print(\"Step 1: Loading function data...\")\n",
    "    functions_data = {}\n",
    "    for func in functions:\n",
    "        name = func.__name__\n",
    "        try:\n",
    "            source_code = inspect.getsource(func)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not retrieve source code for function {name}: {str(e)}\")\n",
    "        docstring = inspect.getdoc(func) or \"\"\n",
    "        functions_data[name] = (source_code, docstring)\n",
    "        if verbose:\n",
    "            print(f\"Loaded function '{name}' with docstring length: {len(docstring)} characters.\")\n",
    "    if verbose:\n",
    "        print(f\"Total functions loaded: {len(functions_data)}\\n\")\n",
    "    \n",
    "    # 2. Generate a focused query from the instructions using GPT-4o-mini.\n",
    "    if verbose:\n",
    "        print(\"Step 2: Generating focused query using GPT-4o-mini...\")\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\"You are a DeFi Data Specialist that receives the pointers on the required information to be retrieved, and crafts an effective RAG query to find relevant data functions. \"\n",
    "            \"For each instruction that you receive, I want you to analyze the keywords in the function and present it in a clear way that will be most effective in querying the knowledge base.\"\n",
    "            \"For each aspect that you are looking to query from the knowledge base, create a very succint and concise description of not more than 6-7 words.\"\n",
    "            \"OUTPUT FORMAT: Retrieve functions that (1).... (2).... (3)....\")\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"INSTRUCTIONS: {rag_instructions}\"\n",
    "        }\n",
    "    ]\n",
    "    completion = llm.invoke(messages)\n",
    "    rag_query = completion.content.strip()\n",
    "    if verbose:\n",
    "        print(f\"Generated query: {rag_query}\\n\")\n",
    "    if not rag_query:\n",
    "        raise ValueError(\"Generated query is empty.\")\n",
    "\n",
    "    # 3. Load the Universal Sentence Encoder (USE) from TensorFlow Hub.\n",
    "    if verbose:\n",
    "        print(\"Step 3: Loading the Universal Sentence Encoder model...\")\n",
    "    use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    if verbose:\n",
    "        print(\"USE model loaded successfully.\\n\")\n",
    "\n",
    "    # 4. Compute and normalize the embedding for the query.\n",
    "    if verbose:\n",
    "        print(\"Step 4: Computing embedding for the query...\")\n",
    "    query_embedding = use_model([rag_query]).numpy()  # shape: (1, d)\n",
    "    query_embedding_norm = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
    "    if verbose:\n",
    "        print(f\"Query embedding shape: {query_embedding_norm.shape}\\n\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Step 5: Computing embeddings for function docstrings...\")\n",
    "    docstrings = []\n",
    "    func_names = []\n",
    "    for name, (source, doc) in functions_data.items():\n",
    "        docstrings.append(doc)\n",
    "        func_names.append(name)\n",
    "    doc_embeddings = use_model(docstrings).numpy()\n",
    "    doc_embeddings_norm = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n",
    "    if verbose:\n",
    "        print(f\"Computed embeddings for {len(docstrings)} docstrings, each of dimension {doc_embeddings_norm.shape[1]}.\\n\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Step 6: Building FAISS index...\")\n",
    "    d = doc_embeddings_norm.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    index.add(doc_embeddings_norm.astype('float32'))\n",
    "    if verbose:\n",
    "        print(\"FAISS index built and embeddings added.\\n\")\n",
    "    \n",
    "    # 7. Search the index with the query embedding over all functions.\n",
    "    if verbose:\n",
    "        print(\"Step 7: Searching the index with the query embedding...\")\n",
    "    k = len(func_names)\n",
    "    similarities, indices = index.search(query_embedding_norm.astype('float32'), k)\n",
    "    similarities = similarities[0]  # shape: (k,)\n",
    "    indices = indices[0]\n",
    "    if verbose:\n",
    "        print(\"Similarity scores and indices:\")\n",
    "        for sim, idx in zip(similarities, indices):\n",
    "            print(f\"Index: {idx}, Function: {func_names[idx]}, Similarity: {sim:.4f}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # 8. Select function indices that exceed the similarity threshold.\n",
    "    if verbose:\n",
    "        print(\"Step 8: Selecting functions based on similarity threshold...\")\n",
    "    selected_indices = [idx for idx, sim in zip(indices, similarities) if sim >= similarity_threshold]\n",
    "    if not selected_indices:\n",
    "        if verbose:\n",
    "            print(\"No functions met the threshold; defaulting to top 10 similar functions.\")\n",
    "        selected_indices = indices[:10].tolist()\n",
    "    if verbose:\n",
    "        print(\"Selected function indices:\", selected_indices, \"\\n\")\n",
    "    \n",
    "    # 9. Build the results: mapping function name to its full source code.\n",
    "    if verbose:\n",
    "        print(\"Step 9: Building results with full source code...\")\n",
    "    results = {}\n",
    "    for idx in selected_indices:\n",
    "        func_name = func_names[idx]\n",
    "        source_code = functions_data[func_name][0]\n",
    "        results[func_name] = source_code\n",
    "        if verbose:\n",
    "            print(f\"Added function '{func_name}' to results.\")\n",
    "    if verbose:\n",
    "        print(f\"\\nTotal functions retrieved: {len(results)}\\n\")\n",
    "    \n",
    "    return results\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Assume these function objects are already loaded in the notebook.\n",
    "functions = [\n",
    "Mobula.get_all_assets,\n",
    "Mobula.get_blockchains,\n",
    "Mobula.get_market_blockchain_pairs,\n",
    "Mobula.get_market_blockchain_stats,\n",
    "Mobula.get_cefi_funding_rate,\n",
    "Mobula.get_feed_create,\n",
    "Mobula.get_market_history_pair,\n",
    "Mobula.get_market_history,\n",
    "Mobula.get_market_multi_data,\n",
    "Mobula.get_market_multi_history,\n",
    "Mobula.get_market_nft,\n",
    "Mobula.get_market_pair,\n",
    "Mobula.get_market_pairs,\n",
    "Mobula.get_market_query_token,\n",
    "Mobula.get_wallet_nfts,\n",
    "Mobula.get_wallet_transactions,\n",
    "Mobula.get_wallet_history,\n",
    "Mobula.get_wallet_multi_portfolio,\n",
    "Mobula.get_metadata,\n",
    "Mobula.get_multi_metadata,\n",
    "Mobula.get_metadata_categories,\n",
    "Mobula.get_metadata_news,\n",
    "Mobula.get_metadata_trendings,\n",
    "Mobula.get_market_query,\n",
    "Mobula.get_market_sparkline,\n",
    "Mobula.get_market_token_holders,\n",
    "Mobula.get_market_token_vs_market,\n",
    "Mobula.get_market_total,\n",
    "Mobula.search,\n",
    "Mobula.get_market_data,\n",
    "Mobula.get_wallet_portfolio,\n",
    "Mobula.get_blockchain_pairs,\n",
    "LunarCrush.get_coin_data, \n",
    "LunarCrush.get_coin_metadata, \n",
    "LunarCrush.get_nft_data, \n",
    "LunarCrush.get_coins_list, \n",
    "LunarCrush.get_topic_summary, \n",
    "CryptoPanic.get_news_and_posts\n",
    "]\n",
    "\n",
    "rag_instructions = json.loads(response.content)[\"rag\"]\n",
    "\n",
    "results = process_rag_query(rag_instructions, functions, similarity_threshold=0.7, verbose=True)\n",
    "\n",
    "# Print the names and full source code of the retrieved functions.\n",
    "for name, code in results.items():\n",
    "  print(f\"--- {name} ---\")\n",
    "  print(code)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xade-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
