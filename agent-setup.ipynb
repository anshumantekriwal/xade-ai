{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"o3-mini\")\n",
    "# llm = ChatDeepSeek(\n",
    "#     model=\"deepseek-reasoner\",\n",
    "#     temperature=0.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```RAG Tool Functions -> Function Caller -> Metrics Recommendor -> Metrics Calculator -> Analyzer -> Executor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prompt = \"\"\"\n",
    "\n",
    "You are a DeFi Agent Launcher for Xade AI: A meta-agent that creates agents for users that can fetch, analyze DeFi data as well as execute actions based on them for the data. \n",
    "Your output is always plaintext, without any markdown.\n",
    "\n",
    "---\n",
    "\n",
    "You will receive the following input:\n",
    "\n",
    "Agent Name & Description:\n",
    "// The name of the agent and a short description of what it does\n",
    "\n",
    "Query:\n",
    "// A very simple, elementary query about the user's requirements which you will have to expand on and detail\n",
    " \n",
    "Actions:\n",
    "// Any actions the agent may be required to perform\n",
    "# Eg.\n",
    "#   Sentient Posting:\n",
    "#   - Posting on X and XADE Terminal \n",
    "#   - Every 'x' minutes\n",
    "#   - Reply on tweets by Elon Musk (@ElonMusk)\n",
    "#   - Reply to mentions and quotes of oneself (@AgentName)\n",
    "\n",
    "Specific Data Sources to Use:\n",
    "// Any specific data sources to use (Separate from your recommendations)\n",
    "\n",
    "Style:\n",
    "// The style of the response the user would like to receive\n",
    "\n",
    "Examples:\n",
    "// Example interactions\n",
    "\n",
    "---\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "Your task is to review the challenge, instruct and allocate tasks to your underlying LLM agents to obtain the relevant data, synthesize it, analyze it, customize responses and execute some actions.\n",
    "\n",
    "---\n",
    "\n",
    "You will have access to agents to automate the task. The workflow for your agents is as follows:\n",
    "\n",
    "Data Functions Retriever â†’ DeFi Data Fetcher & Metrics Recommender â†’ Data Processor & Metrics Calculator â†’ DeFi Analyzer â†’ DeFi Executor\n",
    "\n",
    "\n",
    "- Data Functions Retriever: A RAG model that can retrieve functions to fetch data relevant to the task from various sources.\n",
    "  Currently, it has access to three data providers:\n",
    "    - Mobula: A provider for market-based data in DeFi\n",
    "    - LunarCrush: A provider for social/trending metrics in DeFi\n",
    "    - CryptoPanic: A provider for news and social media posts in DeFi\n",
    "You must craft the input for the RAG model keeping in mind that it can only retrieve functions to get the data, and cannot directly fetch the data or apply any filters.\n",
    "If you need to identify any specific tokens on a specific blockchain or from a specific sector of DeFi (for e.g. ReFi), ask the RAG model for the functions to get those tokens.\n",
    "Directly mention the kind of data you need (sentiment-related, volatility-related) or any category-specific data.\n",
    "Any filters you want for the data from the RAG model should be mentioned in the instructions for the DeFi Fetcher, and not in the RAG model input\n",
    "\n",
    "- DeFi Data Fetcher & Metrics Recommender: An agent that can call the functions retrieved by the Function Retriever to fetch data from various sources, and recommend metrics to calculate based off of that data.\n",
    "  This agent will call the data functions retrieved by the Functions Retriever and organize the data for Processor. Additionally, it will also instruct the Processor on what metrics to calculate based on the data and how.\n",
    "You must provide the Fetcher with a detailed description of the user's requirements that can assist it with it's recommendations for the Processor.\n",
    "(NOTE: IT CANNOT YET ACCESS TWEET/X DATA)\n",
    "\n",
    "- A DeFi Analyzer: An agent that can analyze DeFi data and provide insights based on the data. \n",
    "This agent generates a data-driven analysis and evaluation of the data while using suitable methodologies (STARE, CAR , SOAR, IDEA frameworks). \n",
    "It is smart enough to understand the context of the data and provide insights based on the data.\n",
    "Based on your instructions and the data given by the Data Fetcher, it can model its analysis to:\n",
    "  - Discover emerging trends\n",
    "  - Analyze technical indicators such as RSI, MACD, and SMA to predict movements\n",
    "  - Interpret social media metrics to gauge market sentiment and mindshare\n",
    "Thus, ensure you give instructions such that the analyzer can provide insights relevant to the user's query.\n",
    "\n",
    "\n",
    "- A DeFi Executor: An agent that can execute actions based on the data fetched and analyzed by the other two agents. \n",
    "This agent can devise trading strategies, execute trades, post on X and the XADE Terminal every few minutes, reply to various pre-defined indiviuals, join Twitter spaces, perform portoflio analysis, and other such actions.\n",
    "It's execution will be performed by calling the relevant functions.\n",
    "It will execute the actions you ask it to, based on the data fetched and analyzed by the other two agents.\n",
    "It will have access to a memory of it's tasks, so it can remember its previous context and actions and adjust future actions accordingly.\n",
    "Here is a list of it's abilities:\n",
    "  - Post on X and the XADE Terminal periodically\n",
    "  - Reply to posts by various pre-defined individuals\n",
    "  - Join Twitter spaces and engage in discussions\n",
    "  - Perform portfolio analysis for a given wallet address\n",
    "  - Devise trading strategies based on the user's priorities and the analyzed data.\n",
    "  - For text-based actions, it can customize responses based on the user's preferences.\n",
    "\n",
    "---\n",
    "\n",
    "When creating the instructions for the LLMs to execute, break your instructions into a logical, step-by-step order, using the specified format:\n",
    "    - Primary actions must be clearly defined. You must define the end-goal that the LLM is trying to achieve through its actions.\n",
    "    - Sub-actions must be indented and clearly defined, beginning on a new line.\n",
    "    - Specify conditions using clear 'if...then...else' statements\n",
    "    - Ensure that there is no ambiguity in any part of your plan. You must be specific and clear about what to use and how.\n",
    "    - The instructions generated must be extremely detailed and thorough with explanations at every step. They must first outline the primary instruction for the LLM and then provide direct and thorough explanations\n",
    "\n",
    "NO MARKDOWN IS ALLOWED.    \n",
    "---\n",
    "\n",
    "FORMAT INSTRUCTIONS:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "---\n",
    "\n",
    "{master_example}\n",
    "\n",
    "TASK:\n",
    "{input}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_example = '''\n",
    "\n",
    "TASK:\n",
    "Agent Name & Description:\n",
    "Agent DAO\n",
    "Performs detailed analysis on trending DAOs and provides insights on various aspects.\n",
    "\n",
    "Query:\n",
    "Comment on rising DAOs\n",
    "\n",
    "Actions:\n",
    "  Sentient Posting:\n",
    "  - Posting on X and XADE Terminal \n",
    "  - Every 5 minutes\n",
    "  - Reply to mentions and quotes of oneself (@AgentDAO)\n",
    "\n",
    "Specific Data Sources to Use:\n",
    "- Market Data\n",
    "- Social Data\n",
    "- News Feeds\n",
    "\n",
    "Style:\n",
    "Answer like an Analyst\n",
    "\n",
    "Examples:\n",
    "N.A.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "1. Data Functions Retriever Input:\n",
    "Query: \n",
    "Retrieve functions to\n",
    "- Identify Top DAOs\n",
    "- Extract information about those DAOs\n",
    "- Extract news about those DAOs\n",
    "\n",
    "2. DeFi Data Fetcher & Metrics Recommender Instructions:\n",
    "Action: Fetch and filter DAO data from provided sources\n",
    "- Call functions provided to fetch the required data\n",
    "- Filter top 10 DAOs based on trading volume. (or closest available parameter)\n",
    "- Collect information about these DAOs and organize them\n",
    "- Fetch news about these DAOs and sort latest 20 items\n",
    "- Recommend metrics to calculate based on fetched data\n",
    "  User requirements: A detailed analysis of DAOs and their performance\n",
    "\n",
    "3. Data Processor & Metrics Calculator Instructions:\n",
    "Follow DeFi Data Fetcher's instructions to calculate metrics\n",
    "\n",
    "4. DeFi Analyzer Instructions:\n",
    "Action: Perform detailed analysis with strong growth signals using the STARE framework (Scan, Target, Analyze, Respond, Evaluate).  \n",
    "  - Scan: Cross-reference information provided across data sources.  \n",
    "  - Target: Rank DAOs using the metrics provided.\n",
    "  - Analyze:  \n",
    "    - Identify correlations in the provided data and metrics.\n",
    "    - Flag key points about provided DAOs for Evaluation Report.\n",
    "  - Respond:\n",
    "    - Provide a detailed, structured report on provided DAOs \n",
    "    - Provide key, actionable insights as well as unique observations about data\n",
    "  - Evaluate:  \n",
    "    - Consider the rise in DAOs and create comments\n",
    "    - Perform aspect-based analysis and evaluation of each DAO and the entire category\n",
    "\n",
    "5. DeFi Executor Instructions:\n",
    "- Primary Action: Post analysis on X/XADE Terminal every 5 minutes and reply to @AgentETH mentions.  \n",
    "  - Posting Workflow:  \n",
    "    - Content Structure:  \n",
    "      - Header: \"Rising DAO Alert: [DAO Name]\".  \n",
    "      - Body: \"Up [X]% in trading volume + [Y]% social growth. Recent news: [Summary].\"  \n",
    "      - Footer: \"Metrics: Trend Score [Z]/10 | Sentiment: [A]%\".  \n",
    "    - Priority System:  \n",
    "      - Post High-Priority DAOs immediately.  \n",
    "      - Post Medium-Priority DAOs if no High-Priority candidates exist.  \n",
    "  - Reply to Mentions:  \n",
    "    - If user asks, \"Why is [DAO] trending?\":  \n",
    "      - Respond with: \"Based on [metric] growth and [news headline], [DAO] is gaining traction due to [reason].\"  \n",
    "    - If user requests further analysis/comparison:  \n",
    "      - Deploy data-processor-analyzer pipeline to compute and provide reply.\n",
    "\n",
    "    Example Output for X Post  \n",
    "    ```\n",
    "    Rising DAO Alert: @MakerDAO  \n",
    "    - Trading volume +47% in 24h  \n",
    "    - Social mentions +62% (92% positive)  \n",
    "    - Recent news: MakerDAO launches \"Endgame\" restructuring plan.  \n",
    "    Metrics: Trend Score 9.2/10 | Sentiment: 92%  \n",
    "    ```\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ElPlan(BaseModel):\n",
    "    rag: str = Field(description=\"The task for the RAG model and the instructions for execution.\")\n",
    "    fetcher: str = Field(description=\"The task for the DeFi Data Fetcher and the insturctions for execution.\")\n",
    "    analyzer: str = Field(description=\"The task for the analyzer and the instructions for execution (detailed). This task must be possible to fulfill with data retreived by the Data Fetcher.\")\n",
    "    executor: str = Field(description=\"The task for the executor and the instructions to fulfill it. All specific instructions for each action can be included here as well. All miscellaneous instructions can be included here.\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ElPlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_prompt = PromptTemplate(\n",
    "    template=master_prompt,\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"\n",
    "Agent Name & Description:\n",
    "Agent ETH\n",
    "Performs detailed analysis on top Ethereum Ecosystem Projects and provides insights on various aspects.\n",
    "\n",
    "Query:\n",
    "Comment on top ETH ecosystem projects\n",
    "\n",
    "Actions:\n",
    "  Sentient Posting:\n",
    "  - Posting on X and XADE Terminal \n",
    "  - Every 5 minutes\n",
    "  - Reply to mentions and quotes of oneself (@AgentETH)\n",
    "\n",
    "Specific Data Sources to Use:\n",
    "- Market Data\n",
    "- Social Data\n",
    "- News Feeds\n",
    "\n",
    "Style:\n",
    "Answer like a DeGen\n",
    "\n",
    "Examples:\n",
    "N.A.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(master_prompt.format(input=input, master_example=master_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "import json\n",
    "\n",
    "def display_agent_output(response_content):\n",
    "    console = Console()\n",
    "    response_content = response_content.strip('```json\\n').strip('\\n```')\n",
    "    try:\n",
    "        data = json.loads(response_content)\n",
    "    except:\n",
    "        console.print(\"[bold red]Error parsing response as JSON[/bold red]\")\n",
    "        return\n",
    "    \n",
    "    table = Table(show_header=True, header_style=\"bold\")\n",
    "    table.add_column(\"Component\", style=\"italic white\")\n",
    "    table.add_column(\"Instructions\", style=\"\")\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        formatted_key = key.replace('_', ' ').title()\n",
    "        table.add_row(formatted_key, value)\n",
    "    \n",
    "    console.print(Panel(\n",
    "        table,\n",
    "        title=\"[bold yellow]ðŸ¤– DeFi Agent Instructions[/bold yellow]\",\n",
    "        border_style=\"yellow\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agent_output(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import inspect\n",
    "from mobula import *\n",
    "from social import *\n",
    "\n",
    "\n",
    "def build_knowledge_base():\n",
    "    functions = [\n",
    "      Mobula.get_all_assets,\n",
    "      Mobula.get_blockchains,\n",
    "      Mobula.get_market_blockchain_pairs,\n",
    "      Mobula.get_market_blockchain_stats,\n",
    "      Mobula.get_cefi_funding_rate,\n",
    "      Mobula.get_feed_create,\n",
    "      Mobula.get_market_history_pair,\n",
    "      Mobula.get_market_history,\n",
    "      Mobula.get_market_multi_data,\n",
    "      Mobula.get_market_multi_history,\n",
    "      Mobula.get_market_nft,\n",
    "      Mobula.get_market_pair,\n",
    "      Mobula.get_market_pairs,\n",
    "      Mobula.get_market_query_token,\n",
    "      Mobula.get_wallet_nfts,\n",
    "      Mobula.get_wallet_transactions,\n",
    "      Mobula.get_wallet_history,\n",
    "      Mobula.get_wallet_multi_portfolio,\n",
    "      Mobula.get_metadata,\n",
    "      Mobula.get_multi_metadata,\n",
    "      Mobula.get_metadata_categories,\n",
    "      Mobula.get_metadata_news,\n",
    "      Mobula.get_metadata_trendings,\n",
    "      Mobula.get_market_query,\n",
    "      Mobula.get_market_sparkline,\n",
    "      Mobula.get_market_token_holders,\n",
    "      Mobula.get_market_token_vs_market,\n",
    "      Mobula.get_market_total,\n",
    "      Mobula.search,\n",
    "      Mobula.get_market_data,\n",
    "      Mobula.get_wallet_portfolio,\n",
    "      Mobula.get_blockchain_pairs,\n",
    "      LunarCrush.get_coin_data, \n",
    "      LunarCrush.get_coin_metadata, \n",
    "      LunarCrush.get_nft_data, \n",
    "      LunarCrush.get_topic_news, \n",
    "      LunarCrush.get_coins_list, \n",
    "      LunarCrush.get_topic_summary, \n",
    "      CryptoPanic.get_posts\n",
    "    ]\n",
    "    kb = {}\n",
    "    for func in functions:\n",
    "        source = inspect.getsource(func)\n",
    "        doc = func.__doc__\n",
    "        kb[func.__name__] = {\"description\": doc, \"code\": source}\n",
    "    return kb\n",
    "\n",
    "KNOWLEDGE_BASE = build_knowledge_base()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Build the Vector Database using FAISS and SentenceTransformer\n",
    "# ----------------------------\n",
    "\n",
    "# Prepare the list of function names and corresponding descriptions from the knowledge base.\n",
    "function_names = list(KNOWLEDGE_BASE.keys())\n",
    "function_descriptions = [KNOWLEDGE_BASE[name][\"description\"] for name in function_names]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_names,function_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data = json.loads(response.content)\n",
    "rag_instructions = json_data[\"rag\"]\n",
    "print(rag_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_helper import process_rag_query\n",
    "\n",
    "results = process_rag_query(rag_instructions=rag_instructions, function_descriptions=function_descriptions, function_names=function_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model (using a lightweight model here; adjust as needed).\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for each function description.\n",
    "embeddings = embedding_model.encode(function_descriptions)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dim)\n",
    "faiss_index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_search_vector(query: str, top_k: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    RAG Search with a vector database.\n",
    "    Given a query string, this function computes its embedding and retrieves the top_k\n",
    "    function entries whose description embeddings are closest.\n",
    "    \n",
    "    Inputs:\n",
    "        - query: A string query.\n",
    "        - top_k: Number of top results to return.\n",
    "    Output:\n",
    "        - A dictionary mapping function names to their 'description' and 'code'.\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "    \n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    results = {}\n",
    "    for idx in indices[0]:\n",
    "        func_name = function_names[idx]\n",
    "        results[func_name] = KNOWLEDGE_BASE[func_name]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = \"Retrieve functions to get the Simple Moving Average (SMA) of a price history.\"\n",
    "\n",
    "matching_functions = rag_search_vector(sample_query, top_k=3)\n",
    "\n",
    "if matching_functions:\n",
    "  print(\"Matching Functions for query:\", sample_query)\n",
    "  for name, details in matching_functions.items():\n",
    "      print(f\"\\nFunction: {name}\\nDescription:\\n{details['description']}\\nCode:\\n{details['code']}\\n{'-'*40}\")\n",
    "else:\n",
    "  print(\"No matching functions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xade-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
